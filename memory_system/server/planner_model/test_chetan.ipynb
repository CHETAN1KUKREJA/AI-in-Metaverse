{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "\n",
    "def login_to_huggingface(token: str):\n",
    "  \"\"\"Logs the user into their Hugging Face account using a provided token.\n",
    "\n",
    "  Args:\n",
    "    token: The Hugging Face access token.\n",
    "  \"\"\"\n",
    "  HfFolder.save_token(token)\n",
    "\n",
    "# Get the token from the user\n",
    "token = \"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\"\n",
    "\n",
    "# Call the function to log in with the provided token\n",
    "login_to_huggingface(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recency_score(timestamp: str, current_time: str = None, decay_factor: float = 0.995) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the recency score using an exponential decay function.\n",
    "    \n",
    "    Args:\n",
    "        timestamp (str): The timestamp string in ISO format of when the memory was created/last accessed\n",
    "        current_time (str): The current time string in ISO format to compare against (default: current time)\n",
    "        decay_factor (float): The decay factor for the exponential decay (default: 0.995)\n",
    "    \n",
    "    Returns:\n",
    "        float: A recency score between 0 and 1, where 1 indicates most recent\n",
    "    \"\"\"\n",
    "    if timestamp is None:\n",
    "        return 1.0  # Return maximum score if no timestamp provided\n",
    "        \n",
    "    # Convert timestamp strings to datetime objects\n",
    "    if current_time is None:\n",
    "        current_time = datetime.now().isoformat()\n",
    "        \n",
    "    timestamp_dt = datetime.fromisoformat(timestamp)\n",
    "    current_time_dt = datetime.fromisoformat(current_time)\n",
    "    \n",
    "    # Calculate the time difference in hours\n",
    "    time_diff = current_time_dt - timestamp_dt\n",
    "    hours_diff = time_diff.total_seconds() / (3600*3)\n",
    "    print(hours_diff)\n",
    "    \n",
    "    # Calculate recency score using exponential decay\n",
    "    recency_score = math.pow(decay_factor, hours_diff)\n",
    "    \n",
    "    # Ensure the score is between 0 and 1\n",
    "    recency_score = max(0.0, min(1.0, recency_score))\n",
    "    \n",
    "    return recency_score\n",
    "\n",
    "def recency_and_importance_score_calculator(doc: str, timestamp: str):\n",
    "    \"\"\"\n",
    "    Calculate the importance score of a document. The parameters considered are Relevency, Recency, Frequency, Personal Impact\n",
    "    \n",
    "    Args:\n",
    "        doc (str): The document text\n",
    "        timestamp (str): ISO format timestamp string\n",
    "    \"\"\"\n",
    "    recency = calculate_recency_score(timestamp)\n",
    "    frequency = 1\n",
    "    personal_impact = 1\n",
    "    weights = {\n",
    "        \"relevency\": 0.25,\n",
    "        \"recency\": 0.25,\n",
    "        \"frequency\": 0.25,\n",
    "        \"personal_impact\": 0.25\n",
    "    }\n",
    "    print(recency)\n",
    "    importance_score = recency * weights[\"recency\"] + frequency * weights[\"frequency\"] + personal_impact * weights[\"personal_impact\"]\n",
    "    \n",
    "    return importance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496.142374947037\n",
      "0.08316452495331485\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "timestamp = \"2024-11-10T14:30:00\"  # ISO format timestamp\n",
    "score = recency_and_importance_score_calculator(\"some document\", timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5207911312383287"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-by-one processing time: 95.1987 seconds\n",
    "Batch processing time: 84.3973 seconds\n",
    "with decoding\n",
    "\n",
    "problem is that the code is astill outputing non valid jsons adn giveing extra stuff with the json so it ma cause error while parsing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing of multiple models for speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mistral overall time 3.6 sec and gpu space is 1984+2628 mb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "import warnings\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class QuantizedMemoryRater:\n",
    "    def __init__(self, model_name=\"mistralai/Mistral-7B-Instruct-v0.2\"):\n",
    "        self.model_name = model_name\n",
    "        self.setup_model()\n",
    "    \n",
    "    def clean_jsonformer_response(self, response, prompt_string):\n",
    "        # Strip leading/trailing spaces from the prompt string and response\n",
    "        prompt_string = prompt_string.strip()\n",
    "        response = response.strip()\n",
    "\n",
    "        # Check if the response starts with the prompt string and remove it\n",
    "        if response.startswith(prompt_string):\n",
    "            response = response[len(prompt_string):].strip()\n",
    "\n",
    "        # Return the cleaned response\n",
    "        return response\n",
    "\n",
    "\n",
    "    def setup_model(self):\n",
    "        # Configure 4-bit quantization\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_use_double_quant=True\n",
    "        )\n",
    "\n",
    "        # Load model with quantization\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name,\n",
    "            quantization_config=quantization_config,\n",
    "            device_map=\"auto\"  # Automatically handle device placement\n",
    "        )\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        \n",
    "        # Set pad token if needed\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Create optimized pipeline\n",
    "        self.pipeline = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_new_tokens=512,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "            temperature=0.1\n",
    "        )\n",
    "    \n",
    "    def generate_prompt(self, memory):\n",
    "        return (\n",
    "            \"On the scale of 1 to 10, where 1 is purely mundane \"\n",
    "            \"(e.g., brushing teeth, making bed) and 10 is extremely poignant \"\n",
    "            \"(e.g., a break-up, college acceptance, life), rate the likely poignancy of the \"\n",
    "            f\"following piece of memory.\\nMemory: {memory}\\n\"\n",
    "            \"Provide just your rating a single number rating:<fill_in> and a explanation in JSON format like this: \"\n",
    "            '{\"explanation\": ...,\"rating\":.. }'\n",
    "            \"provide only 1 json\"\n",
    "        )\n",
    "\n",
    "    def rate_memory(self, memory):\n",
    "        try:\n",
    "            # Generate and parse response\n",
    "            prompt = self.generate_prompt(memory)\n",
    "            result = self.pipeline(prompt, max_new_tokens=512)[0]['generated_text']\n",
    "            \n",
    "            return self.clean_jsonformer_response(result, prompt)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e), \"memory\": memory}\n",
    "\n",
    "rater = QuantizedMemoryRater()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory: attending your first yoga class.\n",
      "Result: object with your rating and explanation.\n",
      "{\n",
      "\"explanation\": \"The first yoga class can be a transformative experience for many people. It can introduce them to a new way of moving their body, connecting with their mind and spirit, and finding inner peace. For some, it may be a turning point in their lives, leading them to a deeper practice and a greater sense of self-awareness. However, for others, it may be a more mundane experience, leaving them feeling indifferent or even disappointed. The poignancy of the first yoga class depends on the individual's personal connection to the practice and their openness to the experience.\",\n",
      "\"rating\": 6\n",
      "}\n",
      "The rating of 6 reflects the fact that the first yoga class can be a significant experience for many people, but it is not always an extremely poignant one. The poignancy of the experience depends on the individual's personal connection to the practice and their openness to the experience. Some people may find the class to be a transformative experience that stays with them for the rest of their lives, while others may find it to be a more mundane experience that does not leave a lasting impact. Ultimately, the first yoga class is a unique experience for every individual, and the poignancy of the memory is subjective and personal.\n",
      "\n",
      "Memory: finding a long-lost photo album in the attic.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"Finding a long-lost photo album in the attic can evoke a range of emotions, from nostalgia and joy to sadness and regret. It can bring back memories of people, places, and times long past, and remind us of the passage of time and the people and experiences that have shaped our lives. However, the poignancy of this experience can vary greatly depending on the specific contents of the album and the context in which it is found. For some, it may be a source of great happiness and fond memories, while for others it may be a bittersweet reminder of lost loved ones or past mistakes. Overall, I would rate this experience a 7 on the scale of 1 to 10, as it has the potential to be a deeply moving and meaningful experience, but the exact emotional impact can depend on the individual and the specific contents of the album.\",\n",
      "\"rating\": 7\n",
      "}\n",
      "\n",
      "Memory: having lunch with a childhood friend after years.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"Reconnecting with a childhood friend after a long time can bring up a range of emotions, from joy and excitement to nostalgia and even sadness, depending on the circumstances of the separation and the current state of the friendship. This memory falls on the higher end of the scale, around a 7, as it represents a meaningful reconnection and a reminder of the past.\",\n",
      "\"rating\": 7\n",
      "}\n",
      "\n",
      "Memory: buying a book from your favorite author at a local store.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"This memory is a 5 on the poignancy scale. While buying a book from a favorite author can be an enjoyable experience, it is not typically a life-changing event. However, it can hold a certain level of significance for avid readers or fans of the author. The memory may bring back feelings of excitement, nostalgia, or appreciation for the author's work.\",\n",
      "\"rating\": 5\n",
      "}\n",
      "\n",
      "Memory: moving into a new apartment.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"Moving into a new apartment is a significant life event, but it is not as emotionally charged as other events such as a break-up or a college acceptance. It can be an exciting time as it represents a fresh start and a new chapter in one's life. However, the poignancy of the memory can vary greatly depending on the specific circumstances surrounding the move, such as leaving behind cherished memories in an old apartment or facing the challenges of setting up a new living space. In general, moving into a new apartment is more of a 5 on the scale, as it is a transitional event that can be both exciting and challenging, but is not typically as emotionally charged as other life events.\",\n",
      "\"rating\": 5\n",
      "}\n",
      "\n",
      "Memory: receiving a handwritten letter from a loved one.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"Receiving a handwritten letter from a loved one is a deeply personal and meaningful experience. It shows that the person took the time to write out their thoughts and feelings, and to send it through the mail, adding an element of anticipation and excitement. The physical act of holding a tangible piece of communication from someone who cares about you can evoke strong emotions and feelings of connection and love.\",\n",
      "\"rating\": 9\n",
      "}\n",
      "\n",
      "Memory: visiting a childhood park after decades.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"The memory of visiting a childhood park after decades can evoke a range of emotions, from nostalgia and bittersweetness to joy and wonder. The park may bring back memories of simpler times, childhood friendships, and carefree moments. However, the passage of time and potential changes to the park can also serve as a reminder of the impermanence of things and the passage of life. The experience can be a poignant reminder of the past and the present, and the fleeting nature of time.\",\n",
      "\"rating\": 7\n",
      "}\n",
      "The memory of visiting a childhood park after decades can evoke a range of emotions, from nostalgia and bittersweetness to joy and wonder. The park may bring back memories of simpler times, childhood friendships, and carefree moments. However, the passage of time and potential changes to the park can also serve as a reminder of the impermanence of things and the passage of life. The experience can be a poignant reminder of the past and the present, and the fleeting nature of time.\n",
      "{\"explanation\": \"The memory of visiting a childhood park after decades can evoke a range of emotions, from nostalgia and bittersweetness to joy and wonder. The park may bring back memories of simpler times, childhood friendships, and carefree moments. However, the passage of time and potential changes to the park can also serve as a reminder of the impermanence of things and the passage of life. The experience can be a poignant reminder of the past and the present, and the fleeting nature of time.\",\n",
      "\"rating\": 7\n",
      "}\n",
      "\n",
      "Memory: losing a sentimental necklace on a vacation.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"Losing a sentimental necklace on a vacation can be a significant loss, as it may represent memories or emotions attached to the item. The necklace may have been a gift from a loved one, or it may have been a keepsake from a past trip. Losing it can evoke feelings of sadness, regret, and even guilt. However, the poignancy of the memory may depend on the individual's attachment to the necklace and the circumstances surrounding its loss. For some, it may be a minor inconvenience, while for others, it may be a deeply emotional experience.\",\n",
      "\"rating\": 6\n",
      "}\n",
      "The rating of 6 reflects the general poignancy of losing a sentimental necklace on a vacation, taking into account the potential emotional significance of the item and the circumstances of its loss. However, the exact poignancy may vary from person to person.\n",
      "\n",
      "Memory: winning an impromptu dance competition.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"Winning an impromptu dance competition can be a significant memory for some people as it may represent a sense of achievement, personal growth, and validation. It can also be a reminder of a time when they felt confident, happy, and carefree. However, the poignancy of this memory may vary depending on the individual's personal experiences and attachment to dancing. For some, it may be a fond reminder of a fun moment in their past, while for others it may hold more emotional weight as it represents a turning point in their lives or a source of comfort during difficult times.\",\n",
      "\"rating\": 6\n",
      "}\n",
      "The rating of 6 reflects the fact that while winning an impromptu dance competition can be a meaningful memory, it may not be as poignant as other life events such as a graduation, a wedding, or the birth of a child. However, it can still hold a great deal of significance for the individual and serve as a reminder of a time when they felt accomplished, confident, and joyful.\n",
      "\n",
      "Memory: being stuck in traffic during a thunderstorm.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"Being stuck in traffic during a thunderstorm is a common, everyday experience that can be mildly frustrating, but it does not carry the same emotional weight as more significant life events. The memory of this experience is likely to be rated as a 1 or 2 on the scale.\",\n",
      "\"rating\": 1\n",
      "}\n",
      "\n",
      "Memory: walking a dog for the first time.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"The memory of walking a dog for the first time is likely to be rated as a 3 on the scale of 1 to 10. This experience is not particularly mundane, but it is also not extremely poignant. Walking a dog for the first time can bring joy and a sense of responsibility, but it is not typically a life-changing event. It is an everyday activity that many people engage in, and while it can be enjoyable, it is not typically remembered as a particularly significant moment in one's life.\",\n",
      "\"rating\": 3\n",
      "}\n",
      "\n",
      "Memory: planting a tree in your backyard.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"Planting a tree in your backyard is a meaningful and symbolic act that represents growth, continuity, and connection to the natural world. It can be a poignant experience as it often involves the passage of time, the nurturing of something new, and the creation of a lasting memory. However, the poignancy of this memory can vary depending on the individual's personal connection to the tree, the significance of the tree species, and the circumstances surrounding its planting.\",\n",
      "\"rating\": 6\n",
      "}\n",
      "The memory of planting a tree in your backyard can be a poignant experience, as it represents growth, continuity, and a connection to the natural world. However, the poignancy of this memory can vary depending on the individual's personal connection to the tree, the significance of the tree species, and the circumstances surrounding its planting. For some, it may be a reminder of a loved one or a significant life event, while for others, it may be a simple act of beautifying their home. Overall, I would rate this memory as a 6 on the scale of poignancy.\n",
      "\n",
      "Memory: hearing your favorite song unexpectedly on the radio.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"Hearing a favorite song on the radio can be a pleasant surprise and bring back memories or emotions associated with that song. It can be a brief moment of joy or nostalgia, but it is not as poignant as more significant life events such as a break-up or college acceptance.\",\n",
      "\"rating\": 3\n",
      "}\n",
      "\n",
      "Memory: getting lost while hiking in the woods.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"Getting lost while hiking in the woods can be a scary and disorienting experience, especially if you're alone or with inexperienced hikers. It can also be a moment of reflection and appreciation for nature and the natural world. However, it's not typically a life-altering event, so I would rate it a 4 on the poignancy scale.\",\n",
      "\"rating\": 4\n",
      "}\n",
      "\n",
      "Memory: attending a wedding of a close friend.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"A wedding is a significant life event that marks the beginning of a new chapter in someone's life. Attending a wedding of a close friend adds an emotional layer to the experience as you get to witness and celebrate their happiness and commitment to their partner. It's a reminder of the importance of love and friendship in our lives.\",\n",
      "\"rating\": 8\n",
      "}\n",
      "A wedding is a significant life event that marks the beginning of a new chapter in someone's life. Attending a wedding of a close friend adds an emotional layer to the experience as you get to witness and celebrate their happiness and commitment to their partner. It's a reminder of the importance of love and friendship in our lives.\n",
      "{\"explanation\": \"A wedding is a significant life event that marks the beginning of a new chapter in someone's life. Attending a wedding of a close friend adds an emotional layer to the experience as you get to witness and celebrate their happiness and commitment to their partner. It's a reminder of the importance of love and friendship in our lives.\",\n",
      "\"rating\": 8\n",
      "}\n",
      "This is a very poignant memory as it marks a significant life event for your friend and allows you to celebrate their happiness and commitment to their partner. It also serves as a reminder of the importance of love and friendship in your own life. The rating is an 8 as it is not as emotionally charged as a break-up or a college acceptance, but it is still a very meaningful and memorable experience.\n",
      "\n",
      "Memory: burning your first attempt at cooking a fancy meal.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"The memory of burning your first attempt at cooking a fancy meal can be a source of embarrassment and disappointment, especially if you put a lot of effort and time into the meal. It can also serve as a learning experience and a reminder that mistakes are a natural part of the cooking process. However, the poignancy of this memory may vary depending on the individual's attachment to cooking and the significance of the meal. For some, it may be a minor setback, while for others it may be a more memorable and emotional experience.\",\n",
      "\"rating\": 5\n",
      "}\n",
      "The memory of burning your first attempt at cooking a fancy meal can be a source of embarrassment and disappointment, especially if you put a lot of effort and time into the meal. It can also serve as a learning experience and a reminder that mistakes are a natural part of the cooking process. However, the poignancy of this memory may vary depending on the individual's attachment to cooking and the significance of the meal. For some, it may be a minor setback, while for others it may be a more memorable and emotional experience.\n",
      "{\"explanation\": \"The memory of burning your first attempt at cooking a fancy meal can be a source of embarrassment and disappointment, especially if you put a lot of effort and time into the meal. It can also serve as a learning experience and a reminder that mistakes are a natural part of the cooking process. However, the poignancy of this memory may vary depending on the individual's attachment to cooking and the significance of the meal. For some, it may be a minor setback, while for others it may be a more memorable and emotional experience.\",\n",
      "\"rating\": 5\n",
      "}\n",
      "The memory of burning your first attempt at cooking a fancy meal can be seen as a learning experience and a reminder that mistakes are a natural part of the cooking process. However, the poignancy of this memory may depend on the individual's attachment to cooking and the significance of the meal. For some, it may be a minor setback, while for others it may be a more memorable and emotional experience due to the effort and time put into the meal or the importance of cooking in their lives.\n",
      "{\"explanation\": \"The memory of burning your first attempt at cooking a fancy meal can be seen as a learning experience and a reminder that mistakes are a natural part of the cooking process. However, the po\n",
      "\n",
      "Memory: celebrating a milestone birthday with friends and family.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"A milestone birthday is a significant event in one's life, marking the passing of another year and the potential for new experiences and growth. Celebrating this occasion with friends and family adds an extra layer of meaning and joy, as it highlights the connections and relationships that have been built over time. The shared memories, laughter, and love that come with such gatherings can be deeply moving and memorable, making this a poignant experience.\",\n",
      "\"rating\": 8\n",
      "}\n",
      "A milestone birthday is a significant event in one's life, marking the passing of another year and the potential for new experiences and growth. Celebrating this occasion with friends and family adds an extra layer of meaning and joy, as it highlights the connections and relationships that have been built over time. The shared memories, laughter, and love that come with such gatherings can be deeply moving and memorable, making this a poignant experience.\n",
      "{\"explanation\": \"A milestone birthday is a significant event in one's life, marking the passing of another year and the potential for new experiences and growth. Celebrating this occasion with friends and family adds an extra layer of meaning and joy, as it highlights the connections and relationships that have been built over time. The shared memories, laughter, and love that come with such gatherings can be deeply moving and memorable, making this a poignant experience.\",\n",
      "\"rating\": 8\n",
      "}\n",
      "\n",
      "Memory: watching a sunset on a beach during a solo trip.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"The memory of watching a sunset on a beach during a solo trip can be rated as a 7 on the scale of poignancy. This experience can evoke feelings of introspection, peace, and connection to nature. It can also serve as a reminder of personal growth and independence. However, it may not be as emotionally charged as major life events such as a break-up or a college acceptance.\",\n",
      "\"rating\": 7\n",
      "}\n",
      "\n",
      "Memory: giving a speech at a school reunion.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"A school reunion speech is a significant event for many people, as it provides an opportunity to reconnect with old friends and reminisce about the past. The speech itself may be poignant as it allows the speaker to reflect on their own personal growth and development since graduation, as well as share memories and experiences with their former classmates. However, the level of poignancy may vary depending on the individual's personal connection to their school and classmates, as well as the specific content of the speech.\",\n",
      "\"rating\": 6\n",
      "}\n",
      "A school reunion speech can be a meaningful experience for many people, as it allows them to reconnect with old friends and reflect on their personal growth since graduation. However, the level of poignancy may vary depending on the individual's personal connection to their school and classmates, as well as the specific content of the speech. For some, it may bring back fond memories and evoke strong emotions, while for others it may be a more mundane experience. I would rate this memory as a 6 on the scale of 1 to 10, as it falls in the middle of the spectrum in terms of poignancy. The speech itself may be an opportunity for reflection and reminiscing, but the level of emotion it evokes can vary greatly from person to person.\n",
      "\n",
      "Memory: breaking a personal record at a marathon.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"Breaking a personal record at a marathon is a significant accomplishment, especially for those who train rigorously for months to prepare for the event. It represents a personal triumph over physical and mental challenges, and can be a source of great pride and motivation. However, it may not be as emotionally charged as more life-altering events, such as a break-up or a college acceptance.\",\n",
      "\"rating\": 6\n",
      "}\n",
      "The memory of breaking a personal record at a marathon is a significant accomplishment, but it may not be as emotionally charged as more life-altering events. It represents a personal triumph over physical and mental challenges, and can be a source of great pride and motivation. However, it may not be as emotionally intense as a break-up or a college acceptance.\n",
      "{\"explanation\": \"Breaking a personal record at a marathon is a significant accomplishment, but it may not be as emotionally charged as more life-altering events. It represents a personal triumph over physical and mental challenges, and can be a source of great pride and motivation. However, it may not be as emotionally intense as a break-up or a college acceptance.\",\n",
      "\"rating\": 6\n",
      "}\n",
      "\n",
      "Memory: finding an old diary in a forgotten drawer.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"Finding an old diary can be a bittersweet experience. On one hand, it can bring back memories of past experiences, emotions, and thoughts. On the other hand, it can also be a reminder of how much time has passed and how much has changed since then. The poignancy of this experience can vary greatly depending on the contents of the diary and the emotional connection one has to it.\",\n",
      "\"rating\": 7\n",
      "}\n",
      "The rating of 7 reflects the potential for a mix of nostalgia, introspection, and melancholy that can come with discovering an old diary.\n",
      "\n",
      "Memory: discovering your favorite food at a new restaurant.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"The discovery of a favorite food at a new restaurant can bring feelings of joy and nostalgia, as it reminds us of past experiences and pleasurable memories associated with that food. However, it is not as poignant as major life events, such as a break-up or college acceptance, and is more on the mundane side.\",\n",
      "\"rating\": 3\n",
      "}\n",
      "\n",
      "Memory: receiving an unexpected compliment from a stranger.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"Receiving a compliment from a stranger can be a pleasant surprise and a boost to one's self-esteem. However, it may not be as poignant as more significant life events, such as a break-up or a college acceptance. The memory of a compliment from a stranger may bring a momentary smile or a warm feeling, but it may not have a lasting impact on one's life.\",\n",
      "\"rating\": 3\n",
      "}\n",
      "\n",
      "Memory: dropping your phone into a fountain during a trip.\n",
      "Result: object with explanation and rating.\n",
      "{\n",
      "\"explanation\": \"The memory of dropping your phone into a fountain during a trip may evoke feelings of disappointment, frustration, and even a sense of loss, especially if the phone was new or expensive. However, it is unlikely to be as poignant as a break-up or a life-changing event, as it is primarily a mundane inconvenience that can be resolved with a replacement or repair. The memory may serve as a reminder to be more careful with possessions in the future, but it is not typically a deeply emotional experience.\",\n",
      "\"rating\": 1\n",
      "}\n",
      "109.4985556602478\n"
     ]
    }
   ],
   "source": [
    "start_time =time.time()\n",
    "for i in range(24):\n",
    "    memory = memories[i]\n",
    "    result = rater.rate_memory(memory)\n",
    "    print(f\"\\nMemory: {memory}\")\n",
    "    print(f\"Result: {result}\")\n",
    "processing_time = time.time() - start_time\n",
    "print(processing_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for gemma 2b the results are promising \n",
    "1462MiB+792MiB \n",
    "and 0.6 sec results output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student1/miniconda3/envs/llm_env_achal/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.35s/it]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from langchain_experimental.llms import JsonFormer\n",
    "import warnings\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class QuantizedMemoryRater:\n",
    "    def __init__(self, model_name=\"google/gemma-2b-it\"):\n",
    "        self.model_name = model_name\n",
    "        self.setup_model()\n",
    "    \n",
    "    def clean_jsonformer_response(self,response, prompt_string):\n",
    "        # Strip leading/trailing spaces from the prompt string and response\n",
    "        prompt_string = prompt_string.strip()\n",
    "        response = response.strip()\n",
    "\n",
    "        # Check if the response starts with the prompt string and remove it\n",
    "        if response.startswith(prompt_string):\n",
    "            response = response[len(prompt_string):].strip()\n",
    "\n",
    "        # Return the cleaned response\n",
    "        return response\n",
    "\n",
    "\n",
    "    def setup_model(self):\n",
    "        # Configure 4-bit quantization\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_use_double_quant=True\n",
    "        )\n",
    "\n",
    "        # Load model with quantization\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name,\n",
    "            quantization_config=quantization_config,\n",
    "            device_map=\"auto\"  # Automatically handle device placement\n",
    "        )\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        \n",
    "        # Set pad token if needed\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Create optimized pipeline\n",
    "        self.pipeline = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_new_tokens=512,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "    \n",
    "    def get_json_schema(self):\n",
    "        return {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"explanation\": {\"type\": \"string\"},\n",
    "                \"rating\": {\n",
    "                    \"type\": \"string\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"explanation\", \"rating\"]\n",
    "        }\n",
    "    \n",
    "    def generate_prompt(self, memory):\n",
    "        return (\n",
    "            \"give a score either [low ,medium ,high], where low is purely mundane \"\n",
    "            \"(e.g., brushing teeth, making bed) and high is extremely poignant \"\n",
    "            \"(e.g., a break-up, college acceptance, life), rate the likely poignancy of the \"\n",
    "            f\"following piece of memory.\\nMemory: {memory}\\n\"\n",
    "            \"Rating:\"\n",
    "        )\n",
    "\n",
    "    def rate_memory(self, memory):\n",
    "        try:\n",
    "            # Initialize JsonFormer\n",
    "            json_former = JsonFormer(\n",
    "                json_schema=self.get_json_schema(),\n",
    "                pipeline=self.pipeline\n",
    "            )\n",
    "            \n",
    "            # Generate and parse response\n",
    "            prompt = self.generate_prompt(memory)\n",
    "            result = json_former.predict(prompt, stop=[\"Human:\", \"\\n\\n\"])\n",
    "            \n",
    "            return self.clean_jsonformer_response(result,prompt)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e), \"memory\": memory}\n",
    "\n",
    "# Initialize rater with memory optimizations\n",
    "rater = QuantizedMemoryRater()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.62it/s]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "import warnings\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class QuantizedMemoryRater:\n",
    "    def __init__(self, model_name=\"google/gemma-2b-it\"):\n",
    "        self.model_name = model_name\n",
    "        self.setup_model()\n",
    "    \n",
    "    def clean_jsonformer_response(self, response, prompt_string):\n",
    "        # Strip leading/trailing spaces from the prompt string and response\n",
    "        prompt_string = prompt_string.strip()\n",
    "        response = response.strip()\n",
    "\n",
    "        # Check if the response starts with the prompt string and remove it\n",
    "        if response.startswith(prompt_string):\n",
    "            response = response[len(prompt_string):].strip()\n",
    "\n",
    "        # Return the cleaned response\n",
    "        return response\n",
    "\n",
    "\n",
    "    def setup_model(self):\n",
    "        # Configure 4-bit quantization\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_use_double_quant=True\n",
    "        )\n",
    "\n",
    "        # Load model with quantization\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name,\n",
    "            quantization_config=quantization_config,\n",
    "            device_map=\"auto\"  # Automatically handle device placement\n",
    "        )\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        \n",
    "        # Set pad token if needed\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Create optimized pipeline\n",
    "        self.pipeline = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_new_tokens=512,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "    \n",
    "    def generate_prompt(self, memory):\n",
    "        return (\n",
    "            \"On the scale of 1 to 10, where 1 is purely mundane \"\n",
    "            \"(e.g., brushing teeth, making bed) and 10 is extremely poignant \"\n",
    "            \"(e.g., a break-up, college acceptance, life), rate the likely poignancy of the \"\n",
    "            f\"following piece of memory.\\nMemory: {memory}\\n\"\n",
    "            \"Provide your rating and a brief explanation in JSON format like this: \"\n",
    "            '{ \"rating\": ... , \"explanation\": ... }'\n",
    "            \"have a good range if the item is mundane give it low score\"\n",
    "        )\n",
    "\n",
    "    def rate_memory(self, memory):\n",
    "        try:\n",
    "            # Generate and parse response\n",
    "            prompt = self.generate_prompt(memory)\n",
    "            result = self.pipeline(prompt, max_new_tokens=512)[0]['generated_text']\n",
    "            \n",
    "            return self.clean_jsonformer_response(result, prompt)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e), \"memory\": memory}\n",
    "\n",
    "# Initialize rater with memory optimizations\n",
    "rater = QuantizedMemoryRater()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: and a poignant item high score.\n",
      "\n",
      "{ \"rating\": 7, \"explanation\": \"A simple, yet evocative memory that captures the essence of a mundane activity.\" }\n",
      "0.5941722393035889\n"
     ]
    }
   ],
   "source": [
    "start_time =time.time()\n",
    "result = rater.rate_memory(\"yawn\")\n",
    "print(f\"Result: {result}\")\n",
    "processing_time = time.time() - start_time\n",
    "print(processing_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smallest model but not able ot keep it together to give a coherent output with a json466MiB+296MiB \n",
    "also results in 2.0767781734466553 sec\n",
    "ourput someting like this which is really bad\n",
    "\n",
    "Memory: finding a long-lost photo album in the attic.\n",
    "Result: ```json\n",
    "{\n",
    "    \"memory\": {\n",
    "        \"content\": \"Finding a long-lost photo album in the attic\",\n",
    "        \"rating\": 8,\n",
    "        \"reasons_for_pain\": [\n",
    "            \"The act of opening the album was painful due to its age and sentimental value.\",\n",
    "            \"The discovery of such an item often brings up feelings of nostalgia and sadness.\"\n",
    "        ],\n",
    "        \"impact_on_memories\": [\n",
    "            \"It may evoke emotions like sadness, loss, and longing for the past.\"\n",
    "            \"This experience can be deeply personal and impactful.\"\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student1/miniconda3/envs/llm_env_achal/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from langchain_experimental.llms import JsonFormer\n",
    "import warnings\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class QuantizedMemoryRater:\n",
    "    def __init__(self, model_name=\"Qwen/Qwen2.5-0.5B-Instruct\"):\n",
    "        self.model_name = model_name\n",
    "        self.setup_model()\n",
    "    \n",
    "    def clean_jsonformer_response(self,response, prompt_string):\n",
    "        # Strip leading/trailing spaces from the prompt string and response\n",
    "        prompt_string = prompt_string.strip()\n",
    "        response = response.strip()\n",
    "\n",
    "        # Check if the response starts with the prompt string and remove it\n",
    "        if response.startswith(prompt_string):\n",
    "            response = response[len(prompt_string):].strip()\n",
    "\n",
    "        # Return the cleaned response\n",
    "        return response\n",
    "\n",
    "\n",
    "    def setup_model(self):\n",
    "        # Configure 4-bit quantization\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_use_double_quant=True\n",
    "        )\n",
    "\n",
    "        # Load model with quantization\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name,\n",
    "            quantization_config=quantization_config,\n",
    "            device_map=\"auto\"  # Automatically handle device placement\n",
    "        )\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        \n",
    "        # Set pad token if needed\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Create optimized pipeline\n",
    "        self.pipeline = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_new_tokens=512,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "    \n",
    "    def get_json_schema(self):\n",
    "        return {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"rating\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"minimum\": 1,\n",
    "                    \"maximum\": 10\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"rating\"]\n",
    "        }\n",
    "    \n",
    "    def generate_prompt(self, memory):\n",
    "        return (\n",
    "            \"<|im_start|>system\\nYou rate memories on a scale of 1-10 and explain why.<|im_end|>\\n\"\n",
    "            \"<|im_start|>user\\nOn the scale of 1 to 10, where 1 is purely mundane or minimum\"\n",
    "            \"(e.g., brushing teeth, making bed) and 10 is extremely poignant \"\n",
    "            \"(e.g., a break-up, college acceptance, life), rate the likely poignancy of the \"\n",
    "            f\"following piece of memory.\\nMemory: {memory}\\n\"\n",
    "            \"Rating: Provide the output in JSON format.<|im_end|>\\n\"\n",
    "            \"<|im_start|>assistant\\n\"\n",
    "        )\n",
    "\n",
    "    def rate_memory(self, memory):\n",
    "        try:\n",
    "            # Initialize JsonFormer\n",
    "            json_former = JsonFormer(\n",
    "                json_schema=self.get_json_schema(),\n",
    "                pipeline=self.pipeline\n",
    "            )\n",
    "            \n",
    "            # Generate and parse response\n",
    "            prompt = self.generate_prompt(memory)\n",
    "            result = json_former.predict(prompt, stop=[\"Human:\", \"\\n\\n\"])\n",
    "            \n",
    "            return self.clean_jsonformer_response(result,prompt)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e), \"memory\": memory}\n",
    "\n",
    "    # Initialize rater with memory optimizations\n",
    "rater = QuantizedMemoryRater()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.483938217163086\n",
      "\n",
      "Memory: finding a long-lost photo album in the attic.\n",
      "Result: ```json\n",
      "{\n",
      "    \"memory\": {\n",
      "        \"value\": 7,\n",
      "        \"rating\": [\n",
      "            {\n",
      "                \"item\": \"finding\",\n",
      "                \"impact\": 3,\n",
      "                \"level\": \"poignant\"\n",
      "            },\n",
      "            {\n",
      "                \"item\": \"photo album\",\n",
      "                \"impact\": 2,\n",
      "                \"level\": \"mildly meaningful\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "start_time =time.time()\n",
    "memory = \"finding a long-lost photo album in the attic.\"\n",
    "result = rater.rate_memory(memory)\n",
    "processing_time = time.time() - start_time\n",
    "print(processing_time)\n",
    "print(f\"\\nMemory: {memory}\")\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "836MiB +578MiB \n",
    "output in 2.9 sec best \n",
    "it is not very good in output \n",
    "\n",
    "i changed the prompt a bit as it is providing additional information regarding things like aditional explanation like\n",
    "2.804460287094116\n",
    "\n",
    "Memory: finding a long-lost photo album in the attic.\n",
    "Result: `\n",
    "{\n",
    "  \"rating\": 7,\n",
    "  \"description\": \"This memory has an emotional impact that could be described as somewhat poignant, but not overwhelmingly so. It evokes nostalgia and a sense of discovery, which are generally considered positive emotions.\"\n",
    "}\n",
    "`\n",
    "\n",
    "Explanation:\n",
    "- **Rating:** The memory is rated at 7 because it evokes a mix of nostalgic feelings and discoveries, which can be quite touching or meaningful, especially if you have significant personal significance tied to this item. However, it's not as intensely emotionally charged as something like losing a loved one or receiving a major life achievement. Therefore, 7 out of 10 seems appropriate for someone who values such moments in their life.\n",
    "\n",
    "\n",
    "but sometimes it gives good output\n",
    "\n",
    "but if i give a temp of low thing it gives good outputs in 0.9 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from langchain_experimental.llms import JsonFormer\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class QuantizedMemoryRater:\n",
    "    def __init__(self, model_name=\"Qwen/Qwen2.5-1.5B-Instruct\"):\n",
    "        self.model_name = model_name\n",
    "        self.setup_model()\n",
    "    \n",
    "    def clean_jsonformer_response(self, response, prompt_string):\n",
    "        # Strip leading/trailing spaces from the prompt string and response\n",
    "        prompt_string = prompt_string.strip()\n",
    "        response = response.strip()\n",
    "        \n",
    "        # Check if the response starts with the prompt string and remove it\n",
    "        if response.startswith(prompt_string):\n",
    "            response = response[len(prompt_string):].strip()\n",
    "            \n",
    "        # Return the cleaned response\n",
    "        return response\n",
    "\n",
    "    def setup_model(self):\n",
    "        try:\n",
    "            # Load tokenizer first\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "            \n",
    "            # Set pad token if needed\n",
    "            if self.tokenizer.pad_token is None:\n",
    "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            \n",
    "            # Modified quantization config\n",
    "            model_kwargs = {\n",
    "                \"device_map\": \"auto\",\n",
    "                \"torch_dtype\": torch.float16,\n",
    "            }\n",
    "            \n",
    "            # Only add quantization for non-AWQ models\n",
    "            if \"AWQ\" not in self.model_name:\n",
    "                quantization_config = BitsAndBytesConfig(\n",
    "                    load_in_4bit=True,\n",
    "                    bnb_4bit_compute_dtype=torch.float16,\n",
    "                    bnb_4bit_quant_type=\"nf4\",\n",
    "                    bnb_4bit_use_double_quant=True\n",
    "                )\n",
    "                model_kwargs[\"quantization_config\"] = quantization_config\n",
    "            \n",
    "            # Load model\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                self.model_name,\n",
    "                **model_kwargs\n",
    "            )\n",
    "            \n",
    "            # Create optimized pipeline\n",
    "            self.pipeline = pipeline(\n",
    "                \"text-generation\",\n",
    "                model=self.model,\n",
    "                tokenizer=self.tokenizer,\n",
    "                max_new_tokens=512,\n",
    "                torch_dtype=torch.float16,\n",
    "                device_map=\"auto\",\n",
    "                temperature=0.1  \n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in setup_model: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def get_json_schema(self):\n",
    "        return {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"rating\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"minimum\": 1,\n",
    "                    \"maximum\": 10\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"rating\"]\n",
    "        }\n",
    "    \n",
    "    def generate_prompt(self, memory):\n",
    "        return (\n",
    "            \"<|im_start|>system\\nYou rate memories on a scale of 1-10 and explain why.<|im_end|>\\n\"\n",
    "            \"<|im_start|>user\\nOn the scale of 1 to 10, where 1 is purely mundane or minimum\"\n",
    "            \"(e.g., brushing teeth, making bed) and 10 is extremely poignant \"\n",
    "            \"(e.g., a break-up, college acceptance, life), rate the likely poignancy of the \"\n",
    "            f\"following piece of memory.\\nMemory: {memory}\\n\"\n",
    "            \"Rating: Provide the output in JSON format give no additional info outside of json.<|im_end|>\\n\"\n",
    "            \"<|im_start|>assistant\\n\"\n",
    "        )\n",
    "\n",
    "    def rate_memory(self, memory):\n",
    "        try:\n",
    "            # Initialize JsonFormer\n",
    "            json_former = JsonFormer(\n",
    "                json_schema=self.get_json_schema(),\n",
    "                pipeline=self.pipeline\n",
    "            )\n",
    "            \n",
    "            # Generate and parse response\n",
    "            prompt = self.generate_prompt(memory)\n",
    "            result = json_former.predict(prompt, stop=[\"Human:\", \"\\n\\n\"])\n",
    "            \n",
    "            return self.clean_jsonformer_response(result, prompt)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e), \"memory\": memory}\n",
    "    # Initialize rater with memory optim|izations\n",
    "rater = QuantizedMemoryRater()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memories = [\n",
    "    \"attending your first yoga class.\",\n",
    "    \"finding a long-lost photo album in the attic.\",\n",
    "    \"having lunch with a childhood friend after years.\",\n",
    "    \"buying a book from your favorite author at a local store.\",\n",
    "    \"moving into a new apartment.\",\n",
    "    \"receiving a handwritten letter from a loved one.\",\n",
    "    \"visiting a childhood park after decades.\",\n",
    "    \"losing a sentimental necklace on a vacation.\",\n",
    "    \"winning an impromptu dance competition.\",\n",
    "    \"being stuck in traffic during a thunderstorm.\",\n",
    "    \"walking a dog for the first time.\",\n",
    "    \"planting a tree in your backyard.\",\n",
    "    \"hearing your favorite song unexpectedly on the radio.\",\n",
    "    \"getting lost while hiking in the woods.\",\n",
    "    \"attending a wedding of a close friend.\",\n",
    "    \"burning your first attempt at cooking a fancy meal.\",\n",
    "    \"celebrating a milestone birthday with friends and family.\",\n",
    "    \"watching a sunset on a beach during a solo trip.\",\n",
    "    \"giving a speech at a school reunion.\",\n",
    "    \"breaking a personal record at a marathon.\",\n",
    "    \"finding an old diary in a forgotten drawer.\",\n",
    "    \"discovering your favorite food at a new restaurant.\",\n",
    "    \"receiving an unexpected compliment from a stranger.\",\n",
    "    \"dropping your phone into a fountain during a trip.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory: attending your first yoga class.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"Attending your first yoga class can be quite an emotional experience as it represents a significant step towards personal growth and self-discovery.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: finding a long-lost photo album in the attic.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"Finding a long-lost photo album in the attic can evoke strong emotions such as nostalgia, joy, and a sense of discovery. It might also bring back memories from past events or relationships that are significant to you.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: having lunch with a childhood friend after years.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"The memory has an emotional significance but not as profound as a major life event like getting married or losing a loved one. It's more about reconnecting with someone from the past.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: buying a book from your favorite author at a local store.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"This memory has a moderate level of poignancy as it involves purchasing a book by an author you enjoy, which could evoke feelings of nostalgia, anticipation, or personal significance.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: moving into a new apartment.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"The move into a new apartment can be considered moderately poignant because it represents a significant transition in one's living situation, potentially marking a new chapter in their life. It involves leaving behind familiar surroundings and entering an entirely new environment, which often brings about feelings of nostalgia, excitement, and sometimes sadness.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: receiving a handwritten letter from a loved one.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 8,\n",
      "  \"description\": \"The act of receiving a heartfelt, personal message through a physical medium like a handwritten letter can evoke strong emotions such as nostalgia, joy, or sadness depending on the context. It often carries significant sentimental value and can be deeply meaningful.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: visiting a childhood park after decades.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 8,\n",
      "  \"description\": \"The visitation of a childhood park holds significant sentimental value as it brings back vivid memories from one's youth, evoking feelings of nostalgia and fondness for simpler times.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: losing a sentimental necklace on a vacation.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"The loss of a sentimental item like a necklace can evoke strong emotions, especially if it holds personal significance. This could be considered moderately poignant.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: winning an impromptu dance competition.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"The memory of winning an impromptu dance competition would likely be rated as having moderate poignancy. It could evoke strong positive emotions such as joy, pride, and accomplishment, but it might not reach the highest end of the scale due to its unexpected nature.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: being stuck in traffic during a thunderstorm.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"The experience of being stuck in traffic during a thunderstorm can be quite challenging and stressful, but it may not evoke as strong an emotional response compared to more significant events.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: walking a dog for the first time.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"The experience of being with an unfamiliar animal can be both exciting and slightly nervous, especially if it's your first time walking a dog.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: planting a tree in your backyard.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"Planting a tree can be an emotionally significant experience as it represents growth, new beginnings, and personal achievement.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: hearing your favorite song unexpectedly on the radio.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"The experience of hearing your favorite song unexpectedly on the radio can evoke strong positive emotions such as joy, nostalgia, and happiness. It often brings back pleasant memories and feelings of being transported to a happy time in one's past.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: getting lost while hiking in the woods.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"Getting lost while hiking in the woods can be quite an experience, especially if it happens unexpectedly. It's a moment that could lead to anxiety, frustration, and a sense of isolation, which are all significant emotions.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: attending a wedding of a close friend.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"The memory of attending a wedding of a close friend would likely be rated as having moderate poignancy. It could evoke strong feelings of joy, nostalgia, and perhaps even a touch of sadness due to the significance of the event for the individual involved.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: burning your first attempt at cooking a fancy meal.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"The experience of attempting something new and failing can often be quite emotional, especially when it involves a skill that one has been practicing for some time. In this case, the person's first attempt at cooking a fancy meal would likely evoke feelings of disappointment, frustration, and perhaps even embarrassment, as they realize their efforts have not met expectations.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: celebrating a milestone birthday with friends and family.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"The celebration of a milestone birthday typically involves significant personal achievement and often includes close friends and family members who have been there through many years of shared experiences. It can be emotionally meaningful as it marks an important life event that has brought together people from different stages of their lives.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: watching a sunset on a beach during a solo trip.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"The memory of watching a sunset on a beach during a solo trip has significant personal significance but may not be as emotionally profound as a major life event like a breakup or graduation. It evokes feelings of tranquility, beauty, and solitude.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: giving a speech at a school reunion.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"The given memory has a moderate level of poignancy as it involves an important personal event that marks a significant milestone in one's life. It could evoke strong emotions such as nostalgia, pride, or sadness depending on the individual's perspective.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: breaking a personal record at a marathon.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 8,\n",
      "  \"description\": \"The experience would be highly emotional and significant for many people, as it represents an achievement that few can claim to have accomplished. It could evoke feelings of pride, accomplishment, and a sense of personal growth.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: finding an old diary in a forgotten drawer.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"This memory has a moderate level of poignancy as it involves discovering a personal item from the past that holds sentimental value.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: discovering your favorite food at a new restaurant.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"This memory would be considered moderately poignant as it involves an exciting discovery that could lead to future enjoyment but does not evoke strong emotional intensity.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: receiving an unexpected compliment from a stranger.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"The memory of receiving an unexpected compliment from a stranger would be rated as having moderate poignancy. It could evoke feelings of surprise, happiness, and perhaps a sense of vulnerability if the person feels that their true self was not being judged.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Memory: dropping your phone into a fountain during a trip.\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 7,\n",
      "  \"description\": \"The act of dropping a phone into a fountain can be considered somewhat poignant because it involves an unexpected and potentially embarrassing moment that many people have experienced at some point.\"\n",
      "}\n",
      "```\n",
      "27.162262201309204\n"
     ]
    }
   ],
   "source": [
    "start_time =time.time()\n",
    "for i in range(24):\n",
    "    memory = memories[i]\n",
    "    result = rater.rate_memory(memory)\n",
    "    print(f\"\\nMemory: {memory}\")\n",
    "    print(f\"Result: {result}\")\n",
    "processing_time = time.time() - start_time\n",
    "print(processing_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.22it/s]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from langchain_experimental.llms import JsonFormer\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class QuantizedMemoryRater:\n",
    "    def __init__(self, model_name=\"Qwen/Qwen2.5-3B-Instruct\"):\n",
    "        self.model_name = model_name\n",
    "        self.setup_model()\n",
    "    \n",
    "    def clean_jsonformer_response(self, response, prompt_string):\n",
    "        # Strip leading/trailing spaces from the prompt string and response\n",
    "        prompt_string = prompt_string.strip()\n",
    "        response = response.strip()\n",
    "        \n",
    "        # Check if the response starts with the prompt string and remove it\n",
    "        if response.startswith(prompt_string):\n",
    "            response = response[len(prompt_string):].strip()\n",
    "            \n",
    "        # Return the cleaned response\n",
    "        return response\n",
    "\n",
    "    def setup_model(self):\n",
    "        try:\n",
    "            # Load tokenizer first\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "            \n",
    "            # Set pad token if needed\n",
    "            if self.tokenizer.pad_token is None:\n",
    "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            \n",
    "            # Modified quantization config\n",
    "            model_kwargs = {\n",
    "                \"device_map\": \"auto\",\n",
    "                \"torch_dtype\": torch.float16,\n",
    "            }\n",
    "            \n",
    "            # Only add quantization for non-AWQ models\n",
    "            if \"AWQ\" not in self.model_name:\n",
    "                quantization_config = BitsAndBytesConfig(\n",
    "                    load_in_4bit=True,\n",
    "                    bnb_4bit_compute_dtype=torch.float16,\n",
    "                    bnb_4bit_quant_type=\"nf4\",\n",
    "                    bnb_4bit_use_double_quant=True\n",
    "                )\n",
    "                model_kwargs[\"quantization_config\"] = quantization_config\n",
    "            \n",
    "            # Load model\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                self.model_name,\n",
    "                **model_kwargs\n",
    "            )\n",
    "            \n",
    "            # Create optimized pipeline\n",
    "            self.pipeline = pipeline(\n",
    "                \"text-generation\",\n",
    "                model=self.model,\n",
    "                tokenizer=self.tokenizer,\n",
    "                max_new_tokens=512,\n",
    "                torch_dtype=torch.float16,\n",
    "                device_map=\"auto\"\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in setup_model: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def get_json_schema(self):\n",
    "        return {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"rating\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"minimum\": 1,\n",
    "                    \"maximum\": 10\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"rating\"]\n",
    "        }\n",
    "    \n",
    "    def generate_prompt(self, memory):\n",
    "        return (\n",
    "            \"<|im_start|>system\\nYou rate memories on a scale of 1-10 and explain why.<|im_end|>\\n\"\n",
    "            \"<|im_start|>user\\nOn the scale of 1 to 10, where 1 is purely mundane or minimum\"\n",
    "            \"(e.g., brushing teeth, making bed) and 10 is extremely poignant \"\n",
    "            \"(e.g., a break-up, college acceptance, life), rate the likely poignancy of the \"\n",
    "            f\"following piece of memory.\\nMemory: {memory}\\n\"\n",
    "            \"Rating: Provide the output in JSON format.<|im_end|>\\n\"\n",
    "            \"<|im_start|>assistant\\n\"\n",
    "        )\n",
    "\n",
    "    def rate_memory(self, memory):\n",
    "        try:\n",
    "            # Initialize JsonFormer\n",
    "            json_former = JsonFormer(\n",
    "                json_schema=self.get_json_schema(),\n",
    "                pipeline=self.pipeline\n",
    "            )\n",
    "            \n",
    "            # Generate and parse response\n",
    "            prompt = self.generate_prompt(memory)\n",
    "            print(\"tha\")\n",
    "            print(self.pipeline(prompt))\n",
    "            print(\"tha\")\n",
    "            result = json_former.predict(prompt, stop=[\"Human:\", \"\\n\\n\"])\n",
    "            \n",
    "            return self.clean_jsonformer_response(result, prompt)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e), \"memory\": memory}\n",
    "    # Initialize rater with memory optim|izations\n",
    "rater = QuantizedMemoryRater()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tha\n",
      "[{'generated_text': '<|im_start|>system\\nYou rate memories on a scale of 1-10 and explain why.<|im_end|>\\n<|im_start|>user\\nOn the scale of 1 to 10, where 1 is purely mundane or minimum(e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break-up, college acceptance, life), rate the likely poignancy of the following piece of memory.\\nMemory: yawn\\nRating: Provide the output in JSON format.<|im_end|>\\n<|im_start|>assistant\\n```json\\n{\\n  \"rating\": 1,\\n  \"explanation\": \"A yawn is typically a minor involuntary action that occurs under various circumstances, such as boredom, fatigue, or excitement. On the scale provided, it is rated a 1 because it does not evoke strong emotions or significant personal meaning.\"\\n}\\n```'}]\n",
      "tha\n",
      "Result: ```json\n",
      "{\n",
      "  \"rating\": 1,\n",
      "  \"explanation\": \"A yawn is typically a simple reflex action that occurs without much emotional significance. It does not evoke strong emotions or memories. Therefore, this memory would be rated a 1 out of 10.\"\n",
      "}\n",
      "```\n",
      "3.1841771602630615\n"
     ]
    }
   ],
   "source": [
    "start_time =time.time()\n",
    "result = rater.rate_memory(\"yawn\")\n",
    "print(f\"Result: {result}\")\n",
    "processing_time = time.time() - start_time\n",
    "print(processing_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trying out server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import json\n",
    "from chromadb import Collection\n",
    "import requests\n",
    "import json\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "URI_RATING=\"http://127.0.0.1:5000/rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recency_score(timestamp: str, current_time: str = None, decay_factor: float = 0.995) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the recency score using an exponential decay function.\n",
    "    \n",
    "    Args:\n",
    "        timestamp (str): The timestamp string in ISO format of when the memory was created/last accessed\n",
    "        current_time (str): The current time string in ISO format to compare against (default: current time)\n",
    "        decay_factor (float): The decay factor for the exponential decay (default: 0.995)\n",
    "    \n",
    "    Returns:\n",
    "        float: A recency score between 0 and 1, where 1 indicates most recent\n",
    "    \"\"\"\n",
    "    if timestamp is None:\n",
    "        return 1.0  # Return maximum score if no timestamp provided\n",
    "        \n",
    "    # Convert timestamp strings to datetime objects\n",
    "    if current_time is None:\n",
    "        current_time = datetime.now().isoformat()\n",
    "        \n",
    "    timestamp_dt = datetime.fromisoformat(timestamp)\n",
    "    current_time_dt = datetime.fromisoformat(current_time)\n",
    "    \n",
    "    # Calculate the time difference in hours\n",
    "    time_diff = current_time_dt - timestamp_dt\n",
    "    hours_diff = time_diff.total_seconds() / (3600*3)\n",
    "    \n",
    "    # Calculate recency score using exponential decay\n",
    "    recency_score = math.pow(decay_factor, hours_diff)\n",
    "    \n",
    "    # Ensure the score is between 0 and 1\n",
    "    recency_score = max(0.0, min(1.0, recency_score))\n",
    "    \n",
    "    return recency_score\n",
    "\n",
    "def _initial_recency_and_importance_score_calculator(doc: str, timestamp: str):\n",
    "    \"\"\"\n",
    "    Calculate the importance score of a document. \n",
    "    The parameters considered are Relevency, Recency, Frequency, Personal Impact\n",
    "\n",
    "    Args:\n",
    "        doc (str): The document text\n",
    "        timestamp (str): ISO format timestamp string\n",
    "    \"\"\"\n",
    "    recency = calculate_recency_score(timestamp)\n",
    "    frequency = 1  \n",
    "\n",
    "    # Call the memory rating server\n",
    "    try:\n",
    "        response = requests.post(URI_RATING,json={'memory': doc})\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        result = response.json()\n",
    "        if isinstance(result, str):\n",
    "            result = json.loads(result) \n",
    "\n",
    "        print(result[\"rating\"])  # Now you can access the rating\n",
    "        importance = int(result['rating'])    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error calling memory rating server: {e}\")\n",
    "        importance = 5  # Default value if the server call fails\n",
    "\n",
    "    weights = {\n",
    "        \"relevency\": 0.25,\n",
    "        \"recency\": 0.25,\n",
    "        \"frequency\": 0.25,\n",
    "        \"importance\": 0.25\n",
    "    }\n",
    "    \n",
    "    importance_score = (\n",
    "        recency * weights[\"recency\"] + \n",
    "        importance * weights[\"importance\"]\n",
    "    )\n",
    "    \n",
    "    return importance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Importance score: 0.7359401230408389\n"
     ]
    }
   ],
   "source": [
    "doc = \"I went for a walk in the park and saw some beautiful flowers.\"\n",
    "timestamp = \"2025-01-10T10:00:00\"  # Example timestamp in ISO format\n",
    "importance_score = _initial_recency_and_importance_score_calculator(doc, timestamp)\n",
    "print(f\"Importance score: {importance_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retreiver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- INT4:-2050MiB+2298MiB \n",
    "- INT4_NESTED:-1910MiB+2080MiB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student1/miniconda3/envs/llm_env_achal/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel, BitsAndBytesConfig\n",
    "from typing import List, Union, Tuple, Optional, Literal\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import torch.nn as nn\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "class QuantizationType(Enum):\n",
    "    NONE = \"none\"\n",
    "    INT8 = \"int8\"\n",
    "    INT4 = \"int4\"\n",
    "    INT4_NESTED = \"int4_nested\"\n",
    "    FP16 = \"fp16\"\n",
    "\n",
    "@dataclass\n",
    "class QuantizationConfig:\n",
    "    quant_type: QuantizationType = QuantizationType.NONE\n",
    "    compute_dtype: torch.dtype = torch.float32\n",
    "    double_quant: bool = False\n",
    "    quant_scheme: Literal[\"nf4\", \"fp4\"] = \"nf4\"\n",
    "\n",
    "class BaseRetriever:\n",
    "    \"\"\"Base class for retrieval models with configurable quantization\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        quantization: Optional[QuantizationConfig] = None,\n",
    "        device_map: str = \"auto\"\n",
    "    ):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "        # Ensure tokenizer has padding token\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        if quantization is None:\n",
    "            quantization = QuantizationConfig()\n",
    "        \n",
    "        # Configure model loading based on quantization type\n",
    "        model_kwargs = {\"device_map\": device_map}\n",
    "        \n",
    "        if quantization.quant_type != QuantizationType.NONE:\n",
    "            if quantization.quant_type == QuantizationType.FP16:\n",
    "                model_kwargs[\"torch_dtype\"] = torch.float16\n",
    "            else:\n",
    "                bnb_config = BitsAndBytesConfig(\n",
    "                    load_in_8bit=(quantization.quant_type == QuantizationType.INT8),\n",
    "                    load_in_4bit=(quantization.quant_type in \n",
    "                                 [QuantizationType.INT4, QuantizationType.INT4_NESTED]),\n",
    "                    bnb_4bit_compute_dtype=quantization.compute_dtype,\n",
    "                    bnb_4bit_use_double_quant=(quantization.quant_type == \n",
    "                                              QuantizationType.INT4_NESTED),\n",
    "                    bnb_4bit_quant_type=quantization.quant_scheme\n",
    "                )\n",
    "                model_kwargs[\"quantization_config\"] = bnb_config\n",
    "        \n",
    "        self.model = AutoModel.from_pretrained(model_name, **model_kwargs)\n",
    "        \n",
    "    def _compute_similarity(\n",
    "        self,\n",
    "        query_embedding: torch.Tensor,\n",
    "        text_embeddings: torch.Tensor,\n",
    "        k: int,\n",
    "        similarity_metric: str,\n",
    "        texts: List[str]\n",
    "    ) -> Tuple[List[str], List[float]]:\n",
    "        \"\"\"Compute similarities and return top-k results\"\"\"\n",
    "        if similarity_metric == \"cosine\":\n",
    "            similarities = (query_embedding @ text_embeddings.t()).squeeze() * 100\n",
    "            top_k = torch.topk(similarities, min(k, len(texts)))\n",
    "            scores = top_k.values.tolist()\n",
    "        elif similarity_metric == \"euclidean\":\n",
    "            distances = euclidean_distances(\n",
    "                query_embedding.numpy(),\n",
    "                text_embeddings.numpy()\n",
    "            ).squeeze()\n",
    "            top_k = torch.topk(torch.from_numpy(-distances), min(k, len(texts)))\n",
    "            scores = [-x for x in top_k.values.tolist()]\n",
    "        \n",
    "        results = [texts[idx] for idx in top_k.indices]\n",
    "        return results, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SFRMistralRetriever(BaseRetriever):\n",
    "    \"\"\"Enhanced SFR-Mistral Retriever with configurable quantization\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"Salesforce/SFR-Embedding-Mistral\",\n",
    "        quantization: Optional[QuantizationConfig] = None,\n",
    "        batch_size_per_gpu: int = 32,\n",
    "        max_length: int = 4096\n",
    "    ):\n",
    "        super().__init__(model_name, quantization)\n",
    "        self.devices = [f\"cuda:{i}\" for i in range(torch.cuda.device_count())]\n",
    "        self.batch_size_per_gpu = batch_size_per_gpu\n",
    "        self.max_length = max_length\n",
    "        print(f\"Using {len(self.devices)} GPUs: {self.devices}\")\n",
    "\n",
    "    def _last_token_pool(\n",
    "        self,\n",
    "        last_hidden_states: Tensor,\n",
    "        attention_mask: Tensor\n",
    "    ) -> Tensor:\n",
    "        left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "        if left_padding:\n",
    "            return last_hidden_states[:, -1]\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[\n",
    "            torch.arange(batch_size, device=last_hidden_states.device),\n",
    "            sequence_lengths\n",
    "        ]\n",
    "\n",
    "    def _get_detailed_instruct(self, task_description: str, query: str) -> str:\n",
    "        return f'Instruct: {task_description}\\nQuery: {query}'\n",
    "\n",
    "    def get_text_embeddings(\n",
    "        self,\n",
    "        texts: Union[str, List[str]],\n",
    "        task_description: str = None,\n",
    "        normalize: bool = True\n",
    "    ) -> torch.Tensor:\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "\n",
    "        if task_description:\n",
    "            texts = [self._get_detailed_instruct(task_description, query) \n",
    "                    for query in texts]\n",
    "\n",
    "        total_batch_size = self.batch_size_per_gpu * len(self.devices)\n",
    "        all_embeddings = []\n",
    "        \n",
    "        for i in range(0, len(texts), total_batch_size):\n",
    "            batch_texts = texts[i:i + total_batch_size]\n",
    "            batch_dict = self.tokenizer(\n",
    "                batch_texts,\n",
    "                max_length=self.max_length,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            batch_dict = {k: v.to(self.model.device) \n",
    "                         for k, v in batch_dict.items()}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**batch_dict)\n",
    "                batch_embeddings = self._last_token_pool(\n",
    "                    outputs.last_hidden_state,\n",
    "                    batch_dict['attention_mask']\n",
    "                )\n",
    "                all_embeddings.append(batch_embeddings.cpu())\n",
    "\n",
    "        embeddings = torch.cat(all_embeddings, dim=0)\n",
    "        \n",
    "        if normalize:\n",
    "            embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs: ['cuda:0', 'cuda:1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = QuantizationConfig(quant_type=QuantizationType.INT4_NESTED)\n",
    "SFRMistral_retrieval=SFRMistralRetriever(quantization=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample texts  \n",
    "texts = [  \n",
    "    \"This is an example text about dogs.\",  \n",
    "    \"Another example text about cats.\",  \n",
    "    \"This text is about birds and their habitats.\",  \n",
    "    \"This is a longer text about the history of the internet.\",\n",
    "]*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student1/miniconda3/envs/llm_env_achal/lib/python3.9/site-packages/bitsandbytes/nn/modules.py:451: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Tell me about animals\n",
      "Similar texts:\n",
      "- This is an example text about dogs. (score: 65.0625)\n",
      "- This text is about birds and their habitats. (score: 62.3125)\n",
      "- Another example text about cats. (score: 61.5312)\n",
      "- This is a short text about the importance of sleep. (score: 52.8750)\n",
      "- This is a longer text about the history of the internet. (score: 51.6250)\n"
     ]
    }
   ],
   "source": [
    "# Find similar texts  \n",
    "query = \"Tell me about animals\"  \n",
    "task_description = \"Find a text related to animals\"  \n",
    "similar_texts, scores = SFRMistral_retrieval.find_similar_texts(query, texts, task_description)  \n",
    "\n",
    "# Print results  \n",
    "print(\"Query:\", query)  \n",
    "print(\"Similar texts:\")  \n",
    "for text, score in zip(similar_texts, scores):  \n",
    "    print(f\"- {text} (score: {score:.4f})\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 4096])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "SFRMistral_retrieval.get_text_embeddings(texts).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env_achal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
